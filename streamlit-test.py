import streamlit as st
import openai
import os
import json
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import time
import tiktoken
import datetime
import re
import urllib.parse
import requests
# read_sourcefile_code.py ã‹ã‚‰ç›´æ¥é–¢æ•°ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from read_sourcefile_code import (
    read_ipynb, 
    extract_code_and_comments, 
    read_txtfile
)

#UIæ§‹æˆ
title = st.title("ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹è‡ªç¿’è£œåŠ©ãƒ„ãƒ¼ãƒ«")
openai_api_key = st.text_input("OpenAI API Key", key="chatbot_api_key", type="password")
pick_txt = st.markdown("**å®Ÿè¡Œæ©Ÿèƒ½ã‚’é¸æŠã—ã¦ãã ã•ã„**")
choice_solution=st.selectbox("pick one",["1.é¡ä¼¼ã‚½ãƒ¼ã‚¹è¦ç´„","2.ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯"])
up_file = st.file_uploader("åˆ†æã™ã‚‹ã‚½ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„(2.ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯é¸æŠæ™‚ã®ã¿)", type=["ipynb","py","txt","R"])

# 1~10 ã®ãƒªã‚¹ãƒˆã‚’ä½œæˆ
options = list(range(1, 11))
# ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚’ 3 ã«è¨­å®š 
ref_number = st.selectbox("æ¤œç´¢ã™ã‚‹å‚è€ƒã‚³ãƒ¼ãƒ‰ã®æ•°ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚", options, index=2)

# overview
overview_txt = st.text_area("åˆ†æã™ã‚‹ã‚½ãƒ¼ã‚¹ã®overviewã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")

#ã‚¹ã‚³ã‚¢å…¥åŠ›æ¬„
myscore, aimedscore = st.columns(2)
# å·¦å´ã®å…¥åŠ›æ¬„
with myscore:
    self_score = st.number_input(
        "è‡ªèº«ã®ã‚¹ã‚³ã‚¢ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„(2.ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯é¸æŠæ™‚ã®ã¿)",
        min_value=0.0,  # æœ€å°å€¤ã‚’å°æ•°ã«è¨­å®š
        max_value=100.0,  # æœ€å¤§å€¤ã‚’å°æ•°ã«è¨­å®š
        value=0.0,  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’0.00000ã«è¨­å®š
        step=0.00001,  # å°æ•°ç‚¹ä»¥ä¸‹5æ¡ã¾ã§ã®ã‚¹ãƒ†ãƒƒãƒ—
        format="%.5f",  # å°æ•°ç‚¹ä»¥ä¸‹5æ¡ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
        key="self_score"
    )

# å³å´ã®å…¥åŠ›æ¬„
with aimedscore:
    target_score = st.number_input(
        "ç›®æŒ‡ã™ã‚¹ã‚³ã‚¢ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„(2.ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯é¸æŠæ™‚ã®ã¿)",
        min_value=0.0,  # æœ€å°å€¤ã‚’å°æ•°ã«è¨­å®š
        max_value=100.0,  # æœ€å¤§å€¤ã‚’å°æ•°ã«è¨­å®š
        value=0.0,  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’0.00000ã«è¨­å®š
        step=0.00001,  # å°æ•°ç‚¹ä»¥ä¸‹5æ¡ã¾ã§ã®ã‚¹ãƒ†ãƒƒãƒ—
        format="%.5f",  # å°æ•°ç‚¹ä»¥ä¸‹5æ¡ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
        key="target_score"
    )
# ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰
choice_mode=st.selectbox("pick using model",["gpt-4","gpt-4o mini","gpt-4o"])
# ç«¶æŠ€ã‚¿ã‚¤ãƒ—
choice_type=st.selectbox("pick competition type",["Time series","Classification","Regression","Others"])
# è©•ä¾¡æ–¹æ³•
choice_eval=st.selectbox("pick evaluation(2.ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯é¸æŠæ™‚ã®ã¿)",
                        ["Regression Error(MAE,R^2,RMSE,RMSLE)",
                        "Classification",
                        "AUC",
                        "Confusion matrix",
                        "Quadratic weighted kappa",
                        "MAP@K",
                        "Weighted multi-label logarithmic loss",
                        "Others"])

# ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ã®ã‚¿ã‚¤ãƒˆãƒ«ãƒªã‚¹ãƒˆ
models = [
    "XGBoost",
    "Lightgbm",
    "Catboost",
    "Randomforest",
    "linearregression",
    "Pytorch",
    "Tensorflow",
    "Keras",
    "SupportVectorMachine",
    "Gradientboost",
    "LLM",
    "Others"
]

# è¤‡æ•°é¸æŠã®çŠ¶æ…‹ã‚’ç®¡ç†ã™ã‚‹ãŸã‚ã®ãƒªã‚¹ãƒˆ
selected_models = []

# ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ã‚’ä½œæˆ
st.markdown("### ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„:(2.ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯é¸æŠæ™‚ã®ã¿)")
for option in models:
    if st.checkbox(option):
        selected_models.append(option)

# é¸æŠè‚¢ã«å¿œã˜ã¦è¡¨ç¤ºã™ã‚‹å†…å®¹ã‚’æ±ºå®š
prompt_default = ""
if choice_solution == "1.é¡ä¼¼ã‚½ãƒ¼ã‚¹è¦ç´„":
    prompt_default = "Summarize the source code with the following requirements.\n#Requirements\n- Output what is done in the code for EDA, preprocessing, model building, and evaluation methods, respectively.\n- Describe the overall purpose of each of these processes.\n- Indicate at the beginning of the code which part of the code corresponds to each process.\n"
elif choice_solution == "2.ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯":
    prompt_default = "Compare the user's code with the following Kaggle solutions and provide specific feedback for improvement."

st.markdown("### ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å®Ÿè¡Œã™ã‚‹å ´åˆã¯ãƒã‚§ãƒƒã‚¯ã—ã¦ãã ã•ã„ã€‚")
chk_prompt=st.checkbox("ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å®Ÿè¡Œã™ã‚‹ã€‚")

# é¸æŠè‚¢ã«å¿œã˜ãŸå†…å®¹ã§ãƒ†ã‚­ã‚¹ãƒˆã‚¨ãƒªã‚¢ã‚’è¡¨ç¤º
prompt_area = st.text_area("å®Ÿè¡Œã™ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚",prompt_default)

# ãƒœã‚¿ãƒ³
col = st.columns(2)
ex_button=col[0].button("å®Ÿè¡Œ")
cl_button=col[1].button("ã‚¯ãƒªã‚¢")

# GitHub APIã®åŸºæœ¬æƒ…å ±
LOCAL_METADATA_PATH = os.path.join(os.path.dirname(__file__), "metadata")

# ãƒ­ãƒ¼ã‚«ãƒ«ã®metadataãƒ•ã‚©ãƒ«ãƒ€ã‹ã‚‰JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—ã™ã‚‹é–¢æ•°
def fetch_all_metadata_local(directory_path):
    metadata_list = []

    # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èµ°æŸ»
    for filename in os.listdir(directory_path):
        if filename.endswith(".json"):  # JSONãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿å–å¾—
            file_path = os.path.join(directory_path, filename)

            try:
                with open(file_path, "r", encoding="utf-8") as json_file:
                    metadata = json.load(json_file)
                    metadata["folder"] = directory_path  # ãƒ•ã‚©ãƒ«ãƒ€ãƒ‘ã‚¹ã‚’è¿½åŠ 
                    metadata_list.append(metadata)
            except json.JSONDecodeError as e:
                print(f"JSONãƒ‡ã‚³ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {filename}, ã‚¨ãƒ©ãƒ¼å†…å®¹: {e}")
            except Exception as e:
                print(f"ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {filename}, ã‚¨ãƒ©ãƒ¼å†…å®¹: {e}")

    return metadata_list

# è©•ä¾¡æ–¹æ³•ã¨ç«¶æŠ€ã‚¿ã‚¤ãƒ—ãŒä¸€è‡´ã™ã‚‹ä¸­ã‹ã‚‰overviewã®é¡ä¼¼åº¦ãŒé«˜ã„3ã¤ã‚’å–å¾—
def find_similar_overview(input_overview, metadata_list):
    # é¡ä¼¼åº¦è¨ˆç®—ã®ãŸã‚ã®ãƒªã‚¹ãƒˆä½œæˆ
    overviews = [metadata.get("overview", "") for metadata in metadata_list]
    overviews.append(input_overview)  # ãƒ¦ãƒ¼ã‚¶å…¥åŠ›ã‚’ãƒªã‚¹ãƒˆã«è¿½åŠ 
    vectorizer = TfidfVectorizer()
    tfidf_matrix = vectorizer.fit_transform(overviews)

    # ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã‚’è¨ˆç®—
    similarities = cosine_similarity(tfidf_matrix[-1], tfidf_matrix[:-1])[0]

    # ãƒ•ã‚¡ã‚¤ãƒ«åã¨é¡ä¼¼åº¦ã‚’ãƒšã‚¢ã«ã—ã¦è¡¨ç¤º
    filenames = [metadata.get("code", "unknown_file") for metadata in metadata_list]
    similarity_results = list(zip(filenames, similarities))

    # é¡ä¼¼åº¦ã®é«˜ã„é †ã«ä¸¦ã¹æ›¿ãˆ
    similarity_results = sorted(similarity_results, key=lambda x: x[1], reverse=True)

    # é¡ä¼¼åº¦ã®é«˜ã„é †ã«ä¸¦ã¹æ›¿ãˆã¦3ã¤é¸å®š
    top_indices = sorted(range(len(similarities)), key=lambda i: similarities[i], reverse=True)[:ref_number]

    # é¸ã°ã‚ŒãŸãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’è¿”ã™
    return [metadata_list[i] for i in top_indices]

# ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã«åŸºã¥ã„ã¦å‚è€ƒã‚³ãƒ¼ãƒ‰ã‚’é¸å®š
def select_references(user_input, metadata_list):
    references = []
    priorities = []
    print("select_references start")
    # æ¡ä»¶ã”ã¨ã«åˆ†é¡
    for metadata in metadata_list:
        conditions_met = []

        # æ¡ä»¶A: è©•ä¾¡æ–¹æ³•ãŒåŒã˜
        if metadata["evaluation"].lower() == user_input["evaluation"].lower():
            conditions_met.append("A")

        # æ¡ä»¶B: ç«¶æŠ€ã‚¿ã‚¤ãƒ—ãŒåŒã˜
        if metadata["type"].lower() == user_input["type"].lower():
            conditions_met.append("B")

        # metadata["model"]ã‚’å°æ–‡å­—ã«å¤‰æ›
        metadata_model_lower = metadata["model"].lower() if isinstance(metadata["model"], str) else ''
        # user_input["user_model"]ã®å„è¦ç´ ã‚’å°æ–‡å­—ã«å¤‰æ›
        user_model_lower = [model.lower() for model in user_input["user_model"]]

        # æ¡ä»¶C: ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«ãŒéƒ¨åˆ†ä¸€è‡´
        if any(model in metadata_model_lower for model in user_model_lower):
            conditions_met.append("C")

        # æ¡ä»¶ã«åŸºã¥ã„ã¦åˆ†é¡
        priority = len(conditions_met)
        priorities.append({"metadata": metadata, "priority": priority, "conditions_met": conditions_met})

    # å„ªå…ˆé †ã§ã‚½ãƒ¼ãƒˆ
    priorities = sorted(priorities, key=lambda x: (-x["priority"], x["metadata"]["relative score"]))

    # å‚è€ƒã‚½ãƒ¼ã‚¹ã‚’10ä»¶ã«çµã‚Šè¾¼ã¿
    for ref in priorities:
        references.append(ref["metadata"])
        if len(references) == 10:
            break

    return references

#æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«ã®ä¸­èº«ã‚’æ–‡å­—åˆ—ã§å–å¾—
def get_file_strs(file):
    #ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«
    if not file:
        st.info("ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
        st.stop()
  
    #æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿
    # æ‹¡å¼µå­ã‚’ç¢ºèª
    file_extension = os.path.splitext(file.name)[1].lower()  # ãƒ•ã‚¡ã‚¤ãƒ«ã®æ‹¡å¼µå­ã‚’å–å¾—ï¼ˆ.ipynb, .py,.txtï¼‰
    #ãƒ†ã‚­ã‚¹ãƒˆãƒœãƒƒã‚¯ã‚¹ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å®Ÿè¡Œ
    code_str = ""
    if file_extension == ".ipynb" or file_extension == ".R":
        notebook = read_ipynb(file)
        code_str = extract_code_and_comments(notebook)
    elif file_extension == ".py" or file_extension == ".txt":
        code_str = read_txtfile(file)
    else:
        st.write("å¯¾å¿œã—ã¦ã„ãªã„ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã§ã™ã€‚")
        st.stop()
    
    return code_str 

# ãƒ†ã‚­ã‚¹ãƒˆã®ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’è¨ˆç®—
def count_tokens(text, model):
    """ãƒ†ã‚­ã‚¹ãƒˆã®ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’è¨ˆç®—"""
    enc = tiktoken.encoding_for_model(model)
    return len(enc.encode(text))

# ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã‹ã‚‰ã‚³ãƒ¡ãƒ³ãƒˆè¡Œã‚’å‰Šé™¤
def remove_comments_from_code(code):
    """ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã‹ã‚‰ã‚³ãƒ¡ãƒ³ãƒˆè¡Œã‚’å‰Šé™¤"""
    lines = code.split("\n")
    filtered_lines = [line for line in lines if not line.strip().startswith("#")]
    return "\n".join(filtered_lines)

# ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰:.ipynb ã®ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ `# Markdown start` ï½ `# Markdown end` ã®ç¯„å›²ã‚’å‰Šé™¤
def remove_comments_from_ipynb(ipynb_content):
    """
    .ipynb ã®ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ `# Markdown start` ï½ `# Markdown end` ã®ç¯„å›²ã‚’å‰Šé™¤
    :param ipynb_content: `.ipynb` ã‚’ãƒ†ã‚­ã‚¹ãƒˆåŒ–ã—ãŸãƒ‡ãƒ¼ã‚¿
    :return: Markdown ã‚»ãƒ«ã‚’å‰Šé™¤ã—ãŸãƒ†ã‚­ã‚¹ãƒˆ
    """
    # ğŸ”¹ `# Markdown start` ï½ `# Markdown end` ã®ãƒ–ãƒ­ãƒƒã‚¯ã‚’å‰Šé™¤
    cleaned_content = re.sub(r"# Markdown start[\s\S]*?# Markdown end\n?", "", ipynb_content)

    return cleaned_content

# ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ‡ãƒãƒƒã‚°ç”¨ã«ä¿å­˜ã™ã‚‹é–¢æ•°
def save_debug_file(content,src_name):
    """file_content ã‚’ãƒ‡ãƒãƒƒã‚°ç”¨ã« 'src_name.txt' ã®å½¢å¼ã§ä¿å­˜"""
    #timestamp = datetime.datetime.now().strftime("%Y%m%d%H%M%S%f")[:-3]  # ç¾åœ¨æ™‚åˆ»ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
    filename = f"{src_name}.txt"
    
    with open(filename, "w", encoding="utf-8") as file:
        file.write(content)

    print(f"âœ… ãƒ‡ãƒãƒƒã‚°ç”¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜: {filename}")

# å®Ÿè¡Œãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ãŸæ™‚ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³
if ex_button:
    # âœ… å‡¦ç†é–‹å§‹æ™‚åˆ»ã‚’è¨˜éŒ²
    start_time = time.time()

    # å‚è€ƒã‚³ãƒ¼ãƒ‰ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’åé›†
    metadata_list = fetch_all_metadata_local(LOCAL_METADATA_PATH)

    # é¸æŠè‚¢ã«å¿œã˜ã¦è¡¨ç¤ºã™ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå®Ÿè¡Œå†…å®¹ã‚’æ±ºå®š
    prompt_default = ""
    if choice_solution == "1.é¡ä¼¼ã‚½ãƒ¼ã‚¹è¦ç´„":

        #ãƒ¦ãƒ¼ã‚¶ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
        user_input = {
            "evaluation": choice_eval,
            "type": choice_type,
            "overview": overview_txt
        }

        # è©•ä¾¡æ–¹æ³•ãƒ»ç«¶æŠ€ã‚¿ã‚¤ãƒ—ãŒä¸€è‡´ã™ã‚‹ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’çµã‚Šè¾¼ã‚€
        filtered_metadata = [
            metadata for metadata in metadata_list
            if metadata.get("evaluation") and metadata.get("type")  # None ã§ã¯ãªã„ã“ã¨ã‚’ç¢ºèª
            and metadata["evaluation"].strip().lower() == user_input["evaluation"].strip().lower()  # ä½™åˆ†ãªã‚¹ãƒšãƒ¼ã‚¹ã‚’é™¤å»
            and metadata["type"].strip().lower() == user_input["type"].strip().lower()
        ]       

        # è©•ä¾¡æ–¹æ³•ãƒ»ç«¶æŠ€ã‚¿ã‚¤ãƒ—ãŒä¸€è‡´ã™ã‚‹ä¸­ã§ overview ã®é¡ä¼¼åº¦ãŒé«˜ã„3ã¤ã‚’é¸å®š
        if len(filtered_metadata) <= ref_number:
            references = filtered_metadata
        else:
            references = find_similar_overview(
                user_input["overview"],
                filtered_metadata
            )       

        indicative_sentence_for_prompt = prompt_area #æŒ‡ç¤ºæ–‡

    elif choice_solution == "2.ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯":
        code_str = get_file_strs(up_file) #ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰è¨˜è¼‰å†…å®¹
        #ãƒ¦ãƒ¼ã‚¶ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
        user_input = {
            "user_code": code_str,
            "current_score": self_score,
            "target_score": target_score,
            "evaluation": choice_eval,
            "type": choice_type,
            "user_model": selected_models,
            "overview": overview_txt
        }

        # å‚è€ƒã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã‚’é¸å®š
        selected_references = select_references(user_input, metadata_list)

        # é¸å®šã—ãŸå‚è€ƒã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã‹ã‚‰é¡ä¼¼åº¦ã®é«˜ã„overviewã®ã‚½ãƒ¼ã‚¹ã‚’é¸ã¶
        if len(selected_references) <= ref_number:
            references = selected_references
        else:
            references = find_similar_overview(
                user_input["overview"],
                selected_references
            )[:ref_number]

        indicative_sentence_for_prompt = str(prompt_area) + "\n" +"User's current score:\n"+str(user_input['current_score'])+"\nUser's target score:\n"+ str(user_input['target_score'])+"\nUser's evaluation method:"+ str(user_input['evaluation']) + "\nUser's code:"+ str(user_input['user_code']) + "\nPlease compare the reference source code and user's code below and provide feedback, including specific examples of improvements.\nRelevant Kaggle solutions:"#æŒ‡ç¤ºæ–‡

    # URLã®å–å¾—
    # ã‚¯ãƒªãƒƒã‚¯å¯èƒ½ãªãƒªãƒ³ã‚¯ã‚’ Markdown å½¢å¼ã§ä½œæˆ
    url_markdown = "\n".join([f"- [{ref['url']}]({ref['url']})" for ref in references])

    # Streamlit ã§è¡¨ç¤ºï¼ˆãƒªãƒ³ã‚¯ä»˜ãï¼‰
    st.markdown("### Reference Codes")
    st.markdown(url_markdown, unsafe_allow_html=True)

    if chk_prompt:
        # OpenAI APIãƒªã‚¯ã‚¨ã‚¹ãƒˆ
        try:
            #apiã‚­ãƒ¼å…¥åŠ›ãƒã‚§ãƒƒã‚¯
            if not openai_api_key:
                st.info("OpenAI API Keyã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
                st.stop()
            else:
                openai.api_key = openai_api_key  # å…¥åŠ›ã•ã‚ŒãŸAPIã‚­ãƒ¼ã‚’è¨­å®š

            output_contents = []
            request_count = 0  # APIãƒªã‚¯ã‚¨ã‚¹ãƒˆå›æ•°ã®ã‚«ã‚¦ãƒ³ãƒˆ

            for ref in references:
                prompt = ""
                github_url = ref.get("github link")  # GitHubãƒªãƒ³ã‚¯ã‚’å–å¾—
                
                # GitHubãƒªãƒ³ã‚¯ã®æ¤œè¨¼
                if not github_url or github_url.lower() in ["nan", "none", ""] or not github_url.startswith("http"):
                    print(f"ã‚¹ã‚­ãƒƒãƒ—: ç„¡åŠ¹ãªGitHubãƒªãƒ³ã‚¯: {github_url}, ãƒ•ã‚¡ã‚¤ãƒ«: {ref.get('code', 'unknown')}")
                    continue  # GitHubãƒªãƒ³ã‚¯ãŒãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
                
                try:
                    print(f"ğŸ” å…ƒURL: {github_url}")
                    
                    # GitHub URLã®å½¢å¼ã‚’ç¢ºèªã—ã€raw URLã«å¤‰æ›
                    if "/blob/" in github_url:
                        print(f"ğŸ” å…ƒURL: {github_url}")
                        
                        # æœ€ã‚‚ç¢ºå®Ÿãªæ–¹æ³•: URLæ–‡å­—åˆ—ã®ç›´æ¥ç½®æ›ï¼ˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’ä¿æŒï¼‰
                        # https://github.com/owner/repo/blob/branch/path â†’ https://raw.githubusercontent.com/owner/repo/branch/path
                        raw_url = github_url.replace("github.com", "raw.githubusercontent.com").replace("/blob/", "/")
                        print(f"ğŸ” ç›´æ¥ç½®æ›URL: {raw_url}")
                        
                        # URLãŒæ­£ã—ãå¤‰æ›ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
                        if raw_url == github_url:
                            print("âš ï¸ URLå¤‰æ›ãŒè¡Œã‚ã‚Œã¦ã„ã¾ã›ã‚“ï¼")
                        else:
                            print(f"âœ… URLå¤‰æ›æˆåŠŸ: {github_url} â†’ {raw_url}")
                        
                        # URLã‚’ãƒ‘ãƒ¼ã‚¹ã—ã¦æ¤œè¨¼
                        parsed_url = urllib.parse.urlparse(github_url)
                        parsed_raw = urllib.parse.urlparse(raw_url)
                        print(f"ğŸ” å…ƒURL path: {parsed_url.path}")
                        print(f"ğŸ” raw URL path: {parsed_raw.path}")
                        
                        # ãƒ‘ã‚¹éƒ¨åˆ†ã®è§£æï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
                        path_parts = parsed_url.path.split('/')
                        print(f"ğŸ” URLãƒ‘ã‚¹å„éƒ¨åˆ†: {path_parts}")
                        
                        # requestsãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä½¿ç”¨ã—ã¦ç›´æ¥ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—
                        headers = {
                            "Accept": "application/vnd.github.v3.raw",
                            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
                        }
                        
                        print(f"ğŸ” ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ˜ãƒƒãƒ€ãƒ¼: {headers}")
                        print(f"ğŸ” æœ€çµ‚ç”ŸæˆURL: {raw_url}")
                        
                        # URLè§£ææƒ…å ±ã‚’å–å¾—
                        owner = repo = branch = file_path_parts = None
                        if len(path_parts) >= 6 and path_parts[3] == 'blob':
                            owner = path_parts[1]
                            repo = path_parts[2] 
                            branch = path_parts[4]
                            file_path_parts = path_parts[5:]
                        
                        # URLs to tryãƒªã‚¹ãƒˆã‚’è¨­å®šï¼ˆã‚·ãƒ³ãƒ—ãƒ«ã«ï¼‰
                        urls_to_try = [raw_url]
                        
                        # ä»£æ›¿URLã¨ã—ã¦ã€ãƒ‡ã‚³ãƒ¼ãƒ‰ç‰ˆã‚‚è©¦ã™ï¼ˆå¿µã®ãŸã‚ï¼‰
                        if owner and repo and branch and file_path_parts:
                            try:
                                # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹éƒ¨åˆ†ã‚’ãƒ‡ã‚³ãƒ¼ãƒ‰ã—ã¦ã‹ã‚‰å†ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
                                decoded_path_parts = [urllib.parse.unquote(part) for part in file_path_parts]
                                # å„ãƒ‘ãƒ¼ãƒˆã‚’é©åˆ‡ã«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
                                encoded_path_parts = [urllib.parse.quote(part, safe='') for part in decoded_path_parts]
                                encoded_file_path = '/'.join(encoded_path_parts)
                                alternative_raw_url = f"https://raw.githubusercontent.com/{owner}/{repo}/{branch}/{encoded_file_path}"
                                if alternative_raw_url != raw_url:
                                    urls_to_try.append(alternative_raw_url)
                                    print(f"ğŸ” ä»£æ›¿URLï¼ˆå†ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ç‰ˆï¼‰: {alternative_raw_url}")
                            except Exception as e:
                                print(f"âš ï¸ ä»£æ›¿URLç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
                        
                        file_content = None
                        success = False
                        
                        for i, attempt_url in enumerate(urls_to_try):
                            try:
                                # URLã®æœ€çµ‚æ¤œè¨¼ã¨ä¿®æ­£
                                parsed_attempt = urllib.parse.urlparse(attempt_url)
                                # ã‚¹ãƒšãƒ¼ã‚¹ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ã€é©åˆ‡ã«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ãªã„å ´åˆã¯ä¿®æ­£
                                if ' ' in parsed_attempt.path:
                                    # ãƒ‘ã‚¹ã®å„éƒ¨åˆ†ã‚’é©åˆ‡ã«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
                                    path_parts = parsed_attempt.path.split('/')
                                    encoded_parts = []
                                    for part in path_parts:
                                        if part:  # ç©ºæ–‡å­—åˆ—ã§ãªã„å ´åˆã®ã¿å‡¦ç†
                                            # ã¾ãšãƒ‡ã‚³ãƒ¼ãƒ‰ã—ã¦ã‹ã‚‰å†ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
                                            decoded_part = urllib.parse.unquote(part)
                                            encoded_part = urllib.parse.quote(decoded_part, safe='')
                                            encoded_parts.append(encoded_part)
                                        else:
                                            encoded_parts.append(part)
                                    
                                    fixed_path = '/'.join(encoded_parts)
                                    attempt_url = urllib.parse.urlunparse((
                                        parsed_attempt.scheme,
                                        parsed_attempt.netloc,
                                        fixed_path,
                                        parsed_attempt.params,
                                        parsed_attempt.query,
                                        parsed_attempt.fragment
                                    ))
                                    print(f"ğŸ” URLä¿®æ­£å‰: {parsed_attempt.path}")
                                    print(f"ğŸ” URLä¿®æ­£å¾Œ: {fixed_path}")
                                    print(f"ğŸ” URLä¿®æ­£: {attempt_url}")
                                
                                print(f"ğŸ” è©¦è¡Œ {i+1}/{len(urls_to_try)}: {attempt_url}")
                                response = requests.get(attempt_url, headers=headers, timeout=10)
                                print(f"ğŸ” ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {response.status_code}")
                                
                                if response.status_code == 200:
                                    # .ipynbãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆã¯é©åˆ‡ã«å‡¦ç†
                                    if github_url.endswith('.ipynb'):
                                        try:
                                            notebook_data = json.loads(response.text)
                                            file_content = extract_code_and_comments(notebook_data)
                                        except:
                                            file_content = response.text
                                    else:
                                        file_content = response.text
                                    print(f"âœ… ãƒ•ã‚¡ã‚¤ãƒ«å–å¾—æˆåŠŸ: {ref.get('code', 'unknown')}")
                                    success = True
                                    break
                                else:
                                    print(f"âš ï¸ HTTP {response.status_code}: {attempt_url}")
                                    # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®è©³ç´°ã‚’å–å¾—
                                    try:
                                        error_detail = response.text[:500] if response.text else "No response body"
                                        print(f"   ã‚¨ãƒ©ãƒ¼è©³ç´°: {error_detail}")
                                        # 404ã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯GitHubã®ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ç¢ºèª
                                        if response.status_code == 404:
                                            print(f"   â†’ ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™: {attempt_url}")
                                    except:
                                        pass
                            except requests.exceptions.RequestException as e:
                                print(f"âš ï¸ ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼ {attempt_url}: {e}")
                            except Exception as e:
                                print(f"âš ï¸ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ {attempt_url}: {e}")
                        
                        if not success:
                            # ã™ã¹ã¦ã®URLãŒå¤±æ•—ã—ãŸå ´åˆã€è©³ç´°ãªæƒ…å ±ã‚’å‡ºåŠ›
                            print(f"âŒ ã™ã¹ã¦ã®URLè©¦è¡ŒãŒå¤±æ•—ã—ã¾ã—ãŸ:")
                            for i, url in enumerate(urls_to_try):
                                print(f"   è©¦è¡Œ {i+1}: {url}")
                            
                            # ãƒªãƒã‚¸ãƒˆãƒªã®å­˜åœ¨ç¢ºèª
                            if owner and repo:
                                try:
                                    repo_check_url = f"https://api.github.com/repos/{owner}/{repo}"
                                    repo_response = requests.get(repo_check_url, headers=headers, timeout=5)
                                    print(f"ğŸ” ãƒªãƒã‚¸ãƒˆãƒªå­˜åœ¨ç¢ºèª: {repo_check_url} -> {repo_response.status_code}")
                                    if repo_response.status_code == 404:
                                        print(f"   â†’ ãƒªãƒã‚¸ãƒˆãƒªãŒå­˜åœ¨ã—ã¾ã›ã‚“: {owner}/{repo}")
                                    elif repo_response.status_code == 403:
                                        print(f"   â†’ ãƒªãƒã‚¸ãƒˆãƒªã‚¢ã‚¯ã‚»ã‚¹ãŒåˆ¶é™ã•ã‚Œã¦ã„ã¾ã™ï¼ˆãƒ¬ãƒ¼ãƒˆåˆ¶é™ã¾ãŸã¯èªè¨¼ã‚¨ãƒ©ãƒ¼ï¼‰")
                                except Exception as e:
                                    print(f"âš ï¸ ãƒªãƒã‚¸ãƒˆãƒªç¢ºèªã‚¨ãƒ©ãƒ¼: {e}")
                            
                            error_msg = f"File not found (404): All URL attempts failed"
                            if owner and repo:
                                error_msg += f" - Repository: {owner}/{repo}"
                            if file_path_parts:
                                error_msg += f", File: {'/'.join(file_path_parts)}"
                            raise Exception(error_msg)
                    else:
                        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: URLã‚’ç›´æ¥å¤‰æ›ã—ã¦ã‚¢ã‚¯ã‚»ã‚¹
                        try:
                            raw_url = github_url.replace("github.com", "raw.githubusercontent.com").replace("/blob/", "/")
                            headers = {
                                "Accept": "application/vnd.github.v3.raw",
                                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
                            }
                            response = requests.get(raw_url, headers=headers, timeout=10)
                            
                            if response.status_code == 200:
                                if github_url.endswith('.ipynb'):
                                    try:
                                        notebook_data = json.loads(response.text)
                                        file_content = extract_code_and_comments(notebook_data)
                                    except:
                                        file_content = response.text
                                else:
                                    file_content = response.text
                            else:
                                raise Exception(f"Failed to fetch file: {response.status_code}")
                        except Exception as e:
                            raise Exception(f"Error processing GitHub URL: {e}")
                        
                except Exception as e:
                    print(f"âš ï¸ GitHubãƒ•ã‚¡ã‚¤ãƒ«å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
                    print(f"   å…ƒURL: {github_url}")
                    print(f"   ãƒ‡ã‚³ãƒ¼ãƒ‰URL: {urllib.parse.unquote(github_url)}")
                    print(f"   ãƒ•ã‚¡ã‚¤ãƒ«: {ref.get('code', 'unknown')}")
                    st.warning(f"GitHubãƒ•ã‚¡ã‚¤ãƒ«ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {ref.get('code', 'unknown')} - {str(e)}")
                    continue  # ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯ã‚¹ã‚­ãƒƒãƒ—ã—ã¦æ¬¡ã®ãƒ•ã‚¡ã‚¤ãƒ«ã«é€²ã‚€

                #ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå®Ÿè¡Œæ–‡
                prompt = indicative_sentence_for_prompt + "\n" + file_content
                
                save_debug_file(prompt,ref['code'])

                # ğŸ”¹ **ãƒˆãƒ¼ã‚¯ãƒ³æ•°ãŒ30,000è¶…ãˆã‚‹å ´åˆã¯ã‚³ãƒ¡ãƒ³ãƒˆã‚’é™¤å¤–**
                input_tokens = count_tokens(prompt,choice_mode)

                if input_tokens > 30000:
                    print(f"âš ï¸ å…¥åŠ›ãƒˆãƒ¼ã‚¯ãƒ³æ•° {input_tokens} ãŒ 30,000 ã‚’è¶…é â†’ æ¯”è¼ƒãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚³ãƒ¡ãƒ³ãƒˆå‰Šé™¤")

                    if github_url.endswith(".ipynb"):
                        file_content = remove_comments_from_ipynb(file_content)  # .ipynb ã®å ´åˆ
                    else:
                        file_content = remove_comments_from_code(file_content)  # .py / .R ã®å ´åˆ

                    #ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå®Ÿè¡Œæ–‡å†å®šç¾©
                    prompt = indicative_sentence_for_prompt + "\n" + file_content
                    input_tokens = count_tokens(prompt,choice_mode) # å‰Šé™¤å¾Œã®ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’å†è¨ˆç®—

                    if input_tokens > 30000:
                        print(f"âš ï¸ å…¥åŠ›ãƒˆãƒ¼ã‚¯ãƒ³æ•° {input_tokens} ãŒ 30,000 ã‚’è¶…é â†’ æ¯”è¼ƒãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚³ãƒ¡ãƒ³ãƒˆå‰Šé™¤")
                        # æ‹¡å¼µå­ã‚’ç¢ºèª
                        file_extension = os.path.splitext(up_file.name)[1].lower()  # ãƒ•ã‚¡ã‚¤ãƒ«ã®æ‹¡å¼µå­ã‚’å–å¾—ï¼ˆ.ipynb, .py,.txtï¼‰
                        if file_extension == ".ipynb" or file_extension == ".R":
                            code_str = remove_comments_from_ipynb(file_content)  # .ipynb ã®å ´åˆ
                        elif file_extension == ".py" or file_extension == ".txt":
                            code_str = remove_comments_from_code(file_content)  # .py / .R ã®å ´åˆ

                        #ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå®Ÿè¡Œæ–‡å†å®šç¾©
                        prompt = str(prompt_area) + "\n" +"User's current score:\n"+str(user_input['current_score'])+"\nUser's target score:\n"+ str(user_input['target_score'])+"\nUser's evaluation method:"+ str(user_input['evaluation']) + "\nUser's code:"+ code_str + "\nPlease compare the following reference source code with the user code and provide feedback, including specific examples of improvements in the user code.\nRelevant Kaggle solutions:\n"+ file_content#æŒ‡ç¤ºæ–‡
                        input_tokens = count_tokens(prompt,choice_mode) # å‰Šé™¤å¾Œã®ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’å†è¨ˆç®—
                        print(f"å…¥åŠ›ãƒˆãƒ¼ã‚¯ãƒ³æ•° {input_tokens}")
                # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå®Ÿè¡Œæ–‡ã‚’ ã‚’ãƒ‡ãƒãƒƒã‚°ç”¨ã«ä¿å­˜**

                print("*****ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå®Ÿè¡Œ*****")
                input_tokens = count_tokens(prompt,choice_mode)
                response = openai.chat.completions.create(
                    model=choice_mode,  # ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ï¼ˆgpt-4ã‚„gpt-3.5-turboãªã©ï¼‰
                    messages=[  # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒªã‚¹ãƒˆã®æ§‹é€ 
                        {"role": "system", "content": "You are a helpful assistant."},
                        {"role": "user", "content": prompt}
                    ],
                    #max_tokens=2000  # å‡ºåŠ›ã®ãƒˆãƒ¼ã‚¯ãƒ³æ•°åˆ¶é™
                )

                output_text = response.choices[0].message.content.strip()
                output_tokens = count_tokens(output_text,choice_mode)

                # âœ… **1å›ã®å‡ºåŠ›ã”ã¨ã« `text_area` ã«è¡¨ç¤º**
                st.text_area(f"çµæœè¡¨ç¤º {request_count+1}", value=output_text, height=600, key=f"text_area_{request_count}")

                # âœ… **Input / Output ã®ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’è¡¨ç¤º**
                st.write(f"ğŸ“ **å…¥åŠ›ãƒˆãƒ¼ã‚¯ãƒ³æ•°: {input_tokens}**")
                st.write(f"ğŸ’¬ **å‡ºåŠ›ãƒˆãƒ¼ã‚¯ãƒ³æ•°: {output_tokens}**")

                request_count += 1  # ãƒªã‚¯ã‚¨ã‚¹ãƒˆå›æ•°ã‚’å¢—ã‚„ã™

                # âœ… æœ€å¾Œã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã§ãªã‘ã‚Œã°1åˆ†é–“ã®ãƒˆãƒ¼ã‚¯ãƒ³åˆ¶é™ã‚’è€ƒæ…®ã—ã€é©åˆ‡ãªã‚¿ã‚¤ãƒŸãƒ³ã‚°ã§å¾…æ©Ÿ
                if request_count < len(references):
                    if choice_solution == "1.é¡ä¼¼ã‚½ãƒ¼ã‚¹è¦ç´„" and request_count % 3 == 0:
                        print("â³ 3å›ãƒªã‚¯ã‚¨ã‚¹ãƒˆã—ãŸã®ã§ã€1åˆ†é–“å¾…æ©Ÿã—ã¾ã™...")
                        time.sleep(60)  # 3å›ã”ã¨ã«1åˆ†å¾…æ©Ÿ

                    elif choice_solution == "2.ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯":
                        print("â³ 1å›ãƒªã‚¯ã‚¨ã‚¹ãƒˆã—ãŸã®ã§ã€1åˆ†é–“å¾…æ©Ÿã—ã¾ã™...")
                        time.sleep(60)  # 1å›ã”ã¨ã«1åˆ†å¾…æ©Ÿ

        except Exception as e:
             st.error(f"APIãƒªã‚¯ã‚¨ã‚¹ãƒˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

    # âœ… å‡¦ç†çµ‚äº†æ™‚åˆ»ã‚’è¨˜éŒ²
    end_time = time.time()
    # âœ… å®Ÿè¡Œæ™‚é–“ã‚’è¨ˆç®—
    execution_time = end_time - start_time
    # âœ… Streamlit ä¸Šã«å®Ÿè¡Œæ™‚é–“ã‚’è¡¨ç¤º
    st.write(f"ğŸ”¹ **å‡¦ç†æ™‚é–“: {execution_time:.2f} ç§’**")

